{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 3: Factor Analysis & Clustering\n",
        "\n",
        "**Subject Classification using Factor Analysis and Multiple Clustering Methods**\n",
        "\n",
        "This notebook implements the core analytical methodology from the 2021 thesis. Due to high correlation among sexual behavior variables, we use Factor Analysis to extract underlying dimensions, then apply 8 different clustering algorithms to identify behavioral profiles.\n",
        "\n",
        "---\n",
        "\n",
        "## Methodology Overview:\n",
        "\n",
        "### Part A: Test Data Suitability\n",
        "1. **Bartlett's Test of Sphericity** - Test if variables are correlated\n",
        "2. **Kaiser-Meyer-Olkin (KMO) Test** - Measure sampling adequacy\n",
        "\n",
        "### Part B: Factor Analysis\n",
        "3. **Extract Factors** - Principal Component Analysis\n",
        "4. **Eigenvector Analysis** - Determine optimal number of factors\n",
        "5. **Cronbach's Alpha** - Validate factor reliability\n",
        "6. **Variance Explained** - Assess factor adequacy\n",
        "\n",
        "### Part C: Clustering on Factors\n",
        "7. **Apply 8 Clustering Methods:**\n",
        "   - Affinity Propagation\n",
        "   - Agglomerative Clustering\n",
        "   - BIRCH\n",
        "   - OPTICS\n",
        "   - K-Means\n",
        "   - Mean Shift\n",
        "   - Spectral Clustering\n",
        "   - Gaussian Mixture Model\n",
        "\n",
        "8. **Evaluate with 3 Indices:**\n",
        "   - Silhouette Score\n",
        "   - Calinski-Harabasz Index\n",
        "   - Davies-Bouldin Index\n",
        "\n",
        "9. **Select Optimal Clustering** ‚Üí 5 clusters (K-Means, BIRCH, Gaussian agree)\n",
        "\n",
        "---\n",
        "\n",
        "**Author:** Isabella Rodas  \n",
        "**Institution:** Universidad de los Andes  \n",
        "**Thesis Defense:** December 7th, 2021\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Load Clean Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Factor Analysis\n",
        "from factor_analyzer import FactorAnalyzer\n",
        "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity, calculate_kmo\n",
        "\n",
        "# Clustering algorithms\n",
        "from sklearn.cluster import (AffinityPropagation, AgglomerativeClustering, \n",
        "                              Birch, OPTICS, KMeans, MeanShift, SpectralClustering)\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "\n",
        "# Statistical tests\n",
        "from scipy import stats\n",
        "\n",
        "# Visualization\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_palette('husl')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "print(\"‚úì All libraries loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cleaned data from Notebook 2\n",
        "df = pd.read_csv('../Data/1_Preprocess/datos_preprocesados_FA.csv')\n",
        "\n",
        "print(f\"‚úì Loaded clean data: {df.shape[0]} participants √ó {df.shape[1]} variables\")\n",
        "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "\n",
        "# Preview data\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Factor Analysis\n",
        "# Exclude ID and demographic variables, keep behavioral variables only\n",
        "behavioral_vars = df.drop(columns=['ID', 'Sex', 'Age'], errors='ignore')\n",
        "\n",
        "print(f\"\\nBehavioral variables for Factor Analysis: {len(behavioral_vars.columns)}\")\n",
        "print(behavioral_vars.columns.tolist())\n",
        "\n",
        "# Standardize the data (important for FA and clustering)\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(behavioral_vars)\n",
        "data_scaled_df = pd.DataFrame(data_scaled, columns=behavioral_vars.columns)\n",
        "\n",
        "print(f\"\\n‚úì Data standardized (mean=0, std=1)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part A: Test Data Suitability for Factor Analysis\n",
        "\n",
        "Before applying Factor Analysis, we must verify that the data is suitable using two statistical tests.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Bartlett's Test of Sphericity\n",
        "\n",
        "**Purpose:** Tests if the correlation matrix is significantly different from an identity matrix.\n",
        "\n",
        "**Hypotheses:**\n",
        "- H‚ÇÄ: Variables are uncorrelated (identity matrix)\n",
        "- H‚ÇÅ: Variables are correlated (Factor Analysis is appropriate)\n",
        "\n",
        "**Decision Rule:** If p-value < 0.05, reject H‚ÇÄ ‚Üí Factor Analysis is appropriate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform Bartlett's Test\n",
        "chi_square, p_value = calculate_bartlett_sphericity(behavioral_vars)\n",
        "\n",
        "print(\"Bartlett's Test of Sphericity\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Chi-square statistic: {chi_square:.2f}\")\n",
        "print(f\"P-value: {p_value:.2e}\")\n",
        "print(f\"Degrees of freedom: {len(behavioral_vars.columns) * (len(behavioral_vars.columns) - 1) // 2}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(f\"\\n‚úÖ Result: p-value < 0.05\")\n",
        "    print(\"   ‚Üí Reject H‚ÇÄ: Variables ARE correlated\")\n",
        "    print(\"   ‚Üí Factor Analysis is APPROPRIATE\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå Result: p-value >= 0.05\")\n",
        "    print(\"   ‚Üí Cannot reject H‚ÇÄ: Variables may not be correlated enough\")\n",
        "    print(\"   ‚Üí Factor Analysis may not be appropriate\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Kaiser-Meyer-Olkin (KMO) Test\n",
        "\n",
        "**Purpose:** Measures sampling adequacy for Factor Analysis.\n",
        "\n",
        "**Interpretation:**\n",
        "- **KMO > 0.9:** Excellent\n",
        "- **KMO 0.8-0.9:** Very good  \n",
        "- **KMO 0.7-0.8:** Good\n",
        "- **KMO 0.6-0.7:** Acceptable\n",
        "- **KMO < 0.6:** Unacceptable (Factor Analysis not recommended)\n",
        "\n",
        "**Decision Rule:** KMO should be > 0.6 for Factor Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform KMO Test\n",
        "kmo_all, kmo_model = calculate_kmo(behavioral_vars)\n",
        "\n",
        "print(\"Kaiser-Meyer-Olkin (KMO) Test\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Overall KMO Score: {kmo_model:.4f}\")\n",
        "print()\n",
        "\n",
        "# Interpret KMO score\n",
        "if kmo_model >= 0.9:\n",
        "    interpretation = \"Excellent\"\n",
        "    emoji = \"üåü\"\n",
        "elif kmo_model >= 0.8:\n",
        "    interpretation = \"Very Good\"\n",
        "    emoji = \"‚úÖ\"\n",
        "elif kmo_model >= 0.7:\n",
        "    interpretation = \"Good\"\n",
        "    emoji = \"üëç\"\n",
        "elif kmo_model >= 0.6:\n",
        "    interpretation = \"Acceptable\"\n",
        "    emoji = \"‚úì\"\n",
        "else:\n",
        "    interpretation = \"Unacceptable\"\n",
        "    emoji = \"‚ùå\"\n",
        "\n",
        "print(f\"{emoji} Interpretation: {interpretation}\")\n",
        "print(f\"   ‚Üí Factor Analysis is {'APPROPRIATE' if kmo_model >= 0.6 else 'NOT RECOMMENDED'}\")\n",
        "\n",
        "# Show KMO per variable\n",
        "print(f\"\\n\\nKMO per variable:\")\n",
        "print(\"-\"*60)\n",
        "kmo_df = pd.DataFrame({\n",
        "    'Variable': behavioral_vars.columns,\n",
        "    'KMO': kmo_all\n",
        "}).sort_values('KMO', ascending=False)\n",
        "print(kmo_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary: Suitability Tests\n",
        "\n",
        "**Both tests must pass for Factor Analysis to be appropriate.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of suitability tests\n",
        "print(\"=\"*70)\n",
        "print(\"FACTOR ANALYSIS SUITABILITY - SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n1. Bartlett's Test:  {'‚úÖ PASSED' if p_value < 0.05 else '‚ùå FAILED'} (p = {p_value:.2e})\")\n",
        "print(f\"2. KMO Test:         {'‚úÖ PASSED' if kmo_model >= 0.6 else '‚ùå FAILED'} (KMO = {kmo_model:.4f})\")\n",
        "\n",
        "if p_value < 0.05 and kmo_model >= 0.6:\n",
        "    print(f\"\\nüéâ CONCLUSION: Factor Analysis is APPROPRIATE\")\n",
        "    print(\"   Both conditions satisfied ‚Üí Proceeding with Factor Analysis\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  WARNING: Factor Analysis may not be appropriate\")\n",
        "    print(\"   Consider alternative methods or data transformation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part B: Factor Analysis\n",
        "\n",
        "Now that we've confirmed the data is suitable, we extract latent factors using Principal Component Analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Determine Optimal Number of Factors\n",
        "\n",
        "**Methods:**\n",
        "1. **Kaiser Criterion:** Eigenvalues > 1\n",
        "2. **Scree Plot:** Look for \"elbow\" in eigenvalue plot\n",
        "3. **Variance Explained:** Cumulative variance ‚â• 60-70%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform initial factor analysis to get eigenvalues\n",
        "fa_initial = FactorAnalyzer(n_factors=len(behavioral_vars.columns), rotation=None)\n",
        "fa_initial.fit(behavioral_vars)\n",
        "\n",
        "# Get eigenvalues\n",
        "ev, v = fa_initial.get_eigenvalues()\n",
        "\n",
        "# Display eigenvalues\n",
        "print(\"Eigenvalues:\")\n",
        "print(\"=\"*60)\n",
        "for i, eigenvalue in enumerate(ev, 1):\n",
        "    print(f\"Factor {i:2d}: {eigenvalue:.4f} {'‚úì (>1)' if eigenvalue > 1 else ''}\")\n",
        "\n",
        "# Count factors with eigenvalue > 1 (Kaiser criterion)\n",
        "n_factors_kaiser = sum(ev > 1)\n",
        "print(f\"\\nüìä Kaiser Criterion: {n_factors_kaiser} factors have eigenvalue > 1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Scree Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "# Plot 1: Scree plot\n",
        "axes[0].plot(range(1, len(ev)+1), ev, 'bo-', linewidth=2, markersize=8)\n",
        "axes[0].axhline(y=1, color='r', linestyle='--', label='Kaiser Criterion (eigenvalue=1)')\n",
        "axes[0].set_xlabel('Factor Number', fontsize=12)\n",
        "axes[0].set_ylabel('Eigenvalue', fontsize=12)\n",
        "axes[0].set_title('Scree Plot', fontsize=14, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Cumulative variance explained\n",
        "variance_explained = (ev / ev.sum()) * 100\n",
        "cumulative_variance = np.cumsum(variance_explained)\n",
        "\n",
        "axes[1].plot(range(1, len(cumulative_variance)+1), cumulative_variance, 'go-', \n",
        "             linewidth=2, markersize=8)\n",
        "axes[1].axhline(y=60, color='orange', linestyle='--', label='60% threshold')\n",
        "axes[1].axhline(y=70, color='red', linestyle='--', label='70% threshold')\n",
        "axes[1].set_xlabel('Number of Factors', fontsize=12)\n",
        "axes[1].set_ylabel('Cumulative Variance Explained (%)', fontsize=12)\n",
        "axes[1].set_title('Cumulative Variance Explained', fontsize=14, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find number of factors for 70% variance\n",
        "n_factors_70 = np.where(cumulative_variance >= 70)[0][0] + 1 if any(cumulative_variance >= 70) else len(ev)\n",
        "print(f\"\\nüìä Variance Criterion: {n_factors_70} factors explain ‚â•70% of variance\")\n",
        "print(f\"   ({cumulative_variance[n_factors_70-1]:.1f}% cumulative variance)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select optimal number of factors\n",
        "n_factors = n_factors_kaiser  # Use Kaiser criterion\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(f\"SELECTED: {n_factors} factors for analysis\")\n",
        "print(f\"  - Kaiser criterion: {n_factors_kaiser} factors\")\n",
        "print(f\"  - Variance explained: {cumulative_variance[n_factors-1]:.1f}%\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Extract Factors with Rotation\n",
        "\n",
        "**Rotation Method:** Varimax (orthogonal rotation) to maximize interpretability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform factor analysis with selected number of factors\n",
        "fa = FactorAnalyzer(n_factors=n_factors, rotation='varimax')\n",
        "fa.fit(behavioral_vars)\n",
        "\n",
        "# Get factor loadings\n",
        "loadings = fa.loadings_\n",
        "loadings_df = pd.DataFrame(\n",
        "    loadings,\n",
        "    columns=[f'Factor_{i+1}' for i in range(n_factors)],\n",
        "    index=behavioral_vars.columns\n",
        ")\n",
        "\n",
        "print(\"Factor Loadings (after Varimax rotation):\")\n",
        "print(\"=\"*70)\n",
        "print(loadings_df.round(3))\n",
        "\n",
        "# Highlight strong loadings (>0.5 or <-0.5)\n",
        "print(f\"\\n\\nStrong loadings (|loading| > 0.5):\")\n",
        "print(\"-\"*70)\n",
        "for factor in loadings_df.columns:\n",
        "    strong = loadings_df[loadings_df[factor].abs() > 0.5][factor].sort_values(ascending=False)\n",
        "    if len(strong) > 0:\n",
        "        print(f\"\\n{factor}:\")\n",
        "        for var, loading in strong.items():\n",
        "            print(f\"  {var:35s}: {loading:6.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize factor loadings as heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(loadings_df, annot=True, fmt='.2f', cmap='RdBu_r', center=0, \n",
        "            vmin=-1, vmax=1, cbar_kws={'label': 'Loading'})\n",
        "plt.title('Factor Loadings Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xlabel('Factors', fontsize=12)\n",
        "plt.ylabel('Variables', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Calculate Cronbach's Alpha\n",
        "\n",
        "**Purpose:** Measure internal consistency/reliability of each factor.\n",
        "\n",
        "**Interpretation:**\n",
        "- **Œ± > 0.9:** Excellent\n",
        "- **Œ± 0.8-0.9:** Good\n",
        "- **Œ± 0.7-0.8:** Acceptable\n",
        "- **Œ± 0.6-0.7:** Questionable  \n",
        "- **Œ± < 0.6:** Poor (unacceptable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate Cronbach's Alpha for each factor\n",
        "def cronbach_alpha(data):\n",
        "    \\\"\\\"\\\"Calculate Cronbach's Alpha for reliability\\\"\\\"\\\"\n",
        "    n_items = data.shape[1]\n",
        "    if n_items < 2:\n",
        "        return np.nan\n",
        "    item_variances = data.var(axis=0, ddof=1)\n",
        "    total_variance = data.sum(axis=1).var(ddof=1)\n",
        "    alpha = (n_items / (n_items - 1)) * (1 - item_variances.sum() / total_variance)\n",
        "    return alpha\n",
        "\n",
        "print(\"Cronbach's Alpha - Factor Reliability:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i, factor in enumerate(loadings_df.columns, 1):\n",
        "    # Get variables with strong loadings on this factor\n",
        "    strong_vars = loadings_df[loadings_df[factor].abs() > 0.5].index.tolist()\n",
        "    \n",
        "    if len(strong_vars) >= 2:\n",
        "        factor_data = behavioral_vars[strong_vars]\n",
        "        alpha = cronbach_alpha(factor_data)\n",
        "        \n",
        "        # Interpret alpha\n",
        "        if alpha > 0.9:\n",
        "            interp = \"Excellent\"\n",
        "        elif alpha > 0.8:\n",
        "            interp = \"Good\"\n",
        "        elif alpha > 0.7:\n",
        "            interp = \"Acceptable\"\n",
        "        elif alpha > 0.6:\n",
        "            interp = \"Questionable\"\n",
        "        else:\n",
        "            interp = \"Poor\"\n",
        "        \n",
        "        print(f\"\\n{factor}: Œ± = {alpha:.3f} ({interp})\")\n",
        "        print(f\"  Variables ({len(strong_vars)}): {', '.join(strong_vars)}\")\n",
        "    else:\n",
        "        print(f\"\\n{factor}: Not enough variables for reliability test ({len(strong_vars)} vars)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Extract Factor Scores\n",
        "\n",
        "Factor scores represent each participant's position on each extracted factor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get factor scores for each participant\n",
        "factor_scores = fa.transform(behavioral_vars)\n",
        "factor_scores_df = pd.DataFrame(\n",
        "    factor_scores,\n",
        "    columns=[f'Factor_{i+1}' for i in range(n_factors)]\n",
        ")\n",
        "\n",
        "print(f\"‚úì Extracted factor scores for {len(factor_scores_df)} participants\")\n",
        "print(f\"  Shape: {factor_scores_df.shape}\")\n",
        "print(f\"\\nFactor score statistics:\")\n",
        "print(factor_scores_df.describe().round(3))\n",
        "\n",
        "# Add factor scores to main dataframe\n",
        "df_with_factors = pd.concat([df, factor_scores_df], axis=1)\n",
        "\n",
        "print(f\"\\n‚úì Factor scores added to dataset\")\n",
        "print(f\"  Dataset now has {len(df_with_factors.columns)} columns (original + {n_factors} factor scores)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part C: Clustering on Factor Scores\n",
        "\n",
        "Now we apply 8 different clustering algorithms to the extracted factor scores and evaluate each using 3 statistical indices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Prepare Data for Clustering\n",
        "\n",
        "We'll cluster on the factor scores (not the original variables).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use factor scores for clustering\n",
        "X_cluster = factor_scores_df.values\n",
        "\n",
        "print(f\"Clustering data shape: {X_cluster.shape}\")\n",
        "print(f\"  - {X_cluster.shape[0]} participants\")\n",
        "print(f\"  - {X_cluster.shape[1]} factors\")\n",
        "\n",
        "# Factor scores are already somewhat standardized, but ensure consistency\n",
        "X_cluster_scaled = StandardScaler().fit_transform(X_cluster)\n",
        "\n",
        "print(f\"\\n‚úì Data ready for clustering\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Apply 8 Clustering Methods\n",
        "\n",
        "We'll test multiple methods to find the most robust clustering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define clustering models\n",
        "# We'll try different numbers of clusters (3-7) for each method\n",
        "\n",
        "clustering_results = {}\n",
        "\n",
        "print(\"Applying 8 clustering algorithms...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# We'll test with 5 clusters (based on thesis results)\n",
        "# You can adjust this range to test different cluster numbers\n",
        "n_clusters_to_test = [3, 4, 5, 6, 7]\n",
        "\n",
        "for n_clust in n_clusters_to_test:\n",
        "    print(f\"\\nüîµ Testing with {n_clust} clusters:\")\n",
        "    print(\"-\"*70)\n",
        "    \n",
        "    models = {\n",
        "        'Affinity Propagation': None,  # Determines clusters automatically\n",
        "        'Agglomerative': AgglomerativeClustering(n_clusters=n_clust),\n",
        "        'BIRCH': Birch(n_clusters=n_clust),\n",
        "        'OPTICS': OPTICS(min_samples=5),  # Determines clusters automatically\n",
        "        'K-Means': KMeans(n_clusters=n_clust, random_state=42, n_init=10),\n",
        "        'Mean Shift': MeanShift(),  # Determines clusters automatically\n",
        "        'Spectral': SpectralClustering(n_clusters=n_clust, random_state=42),\n",
        "        'Gaussian Mixture': GaussianMixture(n_components=n_clust, random_state=42)\n",
        "    }\n",
        "    \n",
        "    for name, model in models.items():\n",
        "        try:\n",
        "            # Fit model\n",
        "            if name == 'Affinity Propagation':\n",
        "                model = AffinityPropagation(random_state=42)\n",
        "                labels = model.fit_predict(X_cluster_scaled)\n",
        "            elif name == 'Mean Shift':\n",
        "                labels = model.fit_predict(X_cluster_scaled)\n",
        "            elif name == 'OPTICS':\n",
        "                labels = model.fit_predict(X_cluster_scaled)\n",
        "            elif name == 'Gaussian Mixture':\n",
        "                labels = model.fit_predict(X_cluster_scaled)\n",
        "            else:\n",
        "                labels = model.fit_predict(X_cluster_scaled)\n",
        "            \n",
        "            # Check number of clusters found\n",
        "            n_clusters_found = len(np.unique(labels[labels >= 0]))  # Exclude noise (-1)\n",
        "            \n",
        "            # Store results\n",
        "            key = f\"{name}_{n_clust}\"\n",
        "            clustering_results[key] = {\n",
        "                'method': name,\n",
        "                'n_clusters_requested': n_clust,\n",
        "                'n_clusters_found': n_clusters_found,\n",
        "                'labels': labels\n",
        "            }\n",
        "            \n",
        "            print(f\"  ‚úì {name:25s}: {n_clusters_found} clusters found\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  ‚úó {name:25s}: Failed ({str(e)[:50]})\")\n",
        "\n",
        "print(f\"\\n‚úì Tested {len(clustering_results)} clustering configurations\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Evaluate Clustering Quality\n",
        "\n",
        "**Three evaluation indices:**\n",
        "\n",
        "1. **Silhouette Score** [-1, 1]\n",
        "   - Measures how similar objects are within their own cluster vs other clusters\n",
        "   - Higher is better (>0.5 is good)\n",
        "\n",
        "2. **Calinski-Harabasz Index** [0, ‚àû)\n",
        "   - Ratio of between-cluster to within-cluster dispersion\n",
        "   - Higher is better\n",
        "\n",
        "3. **Davies-Bouldin Index** [0, ‚àû)\n",
        "   - Average similarity ratio between clusters\n",
        "   - Lower is better\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate evaluation metrics for each clustering result\n",
        "evaluation_results = []\n",
        "\n",
        "print(\"Evaluating clustering quality...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for key, result in clustering_results.items():\n",
        "    labels = result['labels']\n",
        "    n_clusters = result['n_clusters_found']\n",
        "    \n",
        "    # Skip if too few clusters or noise points dominate\n",
        "    if n_clusters < 2 or (labels == -1).sum() > len(labels) * 0.3:\n",
        "        continue\n",
        "    \n",
        "    # Calculate metrics (only for non-noise points)\n",
        "    valid_idx = labels >= 0\n",
        "    X_valid = X_cluster_scaled[valid_idx]\n",
        "    labels_valid = labels[valid_idx]\n",
        "    \n",
        "    try:\n",
        "        silhouette = silhouette_score(X_valid, labels_valid)\n",
        "        calinski = calinski_harabasz_score(X_valid, labels_valid)\n",
        "        davies_bouldin = davies_bouldin_score(X_valid, labels_valid)\n",
        "        \n",
        "        evaluation_results.append({\n",
        "            'Method': result['method'],\n",
        "            'N_Clusters_Request': result['n_clusters_requested'],\n",
        "            'N_Clusters_Found': n_clusters,\n",
        "            'Silhouette': silhouette,\n",
        "            'Calinski_Harabasz': calinski,\n",
        "            'Davies_Bouldin': davies_bouldin,\n",
        "            'Labels': labels\n",
        "        })\n",
        "    except:\n",
        "        pass  # Skip if metrics can't be calculated\n",
        "\n",
        "# Create results dataframe\n",
        "eval_df = pd.DataFrame(evaluation_results)\n",
        "\n",
        "print(f\"‚úì Evaluated {len(eval_df)} valid clustering results\\n\")\n",
        "\n",
        "# Display results sorted by Silhouette score\n",
        "eval_display = eval_df[['Method', 'N_Clusters_Request', 'N_Clusters_Found', \n",
        "                         'Silhouette', 'Calinski_Harabasz', 'Davies_Bouldin']].copy()\n",
        "eval_display_sorted = eval_display.sort_values('Silhouette', ascending=False)\n",
        "\n",
        "print(\"Clustering Evaluation Results (sorted by Silhouette):\")\n",
        "print(\"=\"*70)\n",
        "print(eval_display_sorted.to_string(index=False))\n",
        "\n",
        "# Highlight top performers\n",
        "print(f\"\\n\\nüèÜ Top 5 by Silhouette Score:\")\n",
        "print(\"-\"*70)\n",
        "top5 = eval_display_sorted.head(5)\n",
        "for idx, row in top5.iterrows():\n",
        "    print(f\"  {row['Method']:25s} ({row['N_Clusters_Found']} clusters): {row['Silhouette']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize evaluation metrics\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Filter to show only 5-cluster solutions for comparison\n",
        "eval_5clust = eval_df[eval_df['N_Clusters_Found'] == 5].sort_values('Silhouette', ascending=False)\n",
        "\n",
        "if len(eval_5clust) > 0:\n",
        "    methods = eval_5clust['Method'].values\n",
        "    \n",
        "    # Plot 1: Silhouette\n",
        "    axes[0].barh(methods, eval_5clust['Silhouette'].values, color='steelblue', edgecolor='black')\n",
        "    axes[0].set_xlabel('Silhouette Score', fontsize=11)\n",
        "    axes[0].set_title('Silhouette Score\\n(Higher is Better)', fontsize=12, fontweight='bold')\n",
        "    axes[0].grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Calinski-Harabasz\n",
        "    axes[1].barh(methods, eval_5clust['Calinski_Harabasz'].values, color='coral', edgecolor='black')\n",
        "    axes[1].set_xlabel('Calinski-Harabasz Index', fontsize=11)\n",
        "    axes[1].set_title('Calinski-Harabasz Index\\n(Higher is Better)', fontsize=12, fontweight='bold')\n",
        "    axes[1].grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    # Plot 3: Davies-Bouldin\n",
        "    axes[2].barh(methods, eval_5clust['Davies_Bouldin'].values, color='lightcoral', edgecolor='black')\n",
        "    axes[2].set_xlabel('Davies-Bouldin Index', fontsize=11)\n",
        "    axes[2].set_title('Davies-Bouldin Index\\n(Lower is Better)', fontsize=12, fontweight='bold')\n",
        "    axes[2].grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    plt.suptitle('Clustering Quality Comparison (5-Cluster Solutions)', \n",
        "                 fontsize=14, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No 5-cluster solutions available for visualization\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Select Optimal Clustering\n",
        "\n",
        "**Thesis Result:** K-Means, BIRCH, and Gaussian Mixture all converged on the same 5 clusters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract 5-cluster solutions from K-Means, BIRCH, and Gaussian\n",
        "kmeans_5 = eval_df[(eval_df['Method'] == 'K-Means') & (eval_df['N_Clusters_Found'] == 5)]\n",
        "birch_5 = eval_df[(eval_df['Method'] == 'BIRCH') & (eval_df['N_Clusters_Found'] == 5)]\n",
        "gaussian_5 = eval_df[(eval_df['Method'] == 'Gaussian Mixture') & (eval_df['N_Clusters_Found'] == 5)]\n",
        "\n",
        "print(\"Comparison of Top 3 Methods (5 clusters):\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if len(kmeans_5) > 0:\n",
        "    print(f\"\\n‚úÖ K-Means:\")\n",
        "    print(f\"   Silhouette: {kmeans_5.iloc[0]['Silhouette']:.4f}\")\n",
        "    print(f\"   Calinski-Harabasz: {kmeans_5.iloc[0]['Calinski_Harabasz']:.2f}\")\n",
        "    print(f\"   Davies-Bouldin: {kmeans_5.iloc[0]['Davies_Bouldin']:.4f}\")\n",
        "\n",
        "if len(birch_5) > 0:\n",
        "    print(f\"\\n‚úÖ BIRCH:\")\n",
        "    print(f\"   Silhouette: {birch_5.iloc[0]['Silhouette']:.4f}\")\n",
        "    print(f\"   Calinski-Harabasz: {birch_5.iloc[0]['Calinski_Harabasz']:.2f}\")\n",
        "    print(f\"   Davies-Bouldin: {birch_5.iloc[0]['Davies_Bouldin']:.4f}\")\n",
        "\n",
        "if len(gaussian_5) > 0:\n",
        "    print(f\"\\n‚úÖ Gaussian Mixture:\")\n",
        "    print(f\"   Silhouette: {gaussian_5.iloc[0]['Silhouette']:.4f}\")\n",
        "    print(f\"   Calinski-Harabasz: {gaussian_5.iloc[0]['Calinski_Harabasz']:.2f}\")\n",
        "    print(f\"   Davies-Bouldin: {gaussian_5.iloc[0]['Davies_Bouldin']:.4f}\")\n",
        "\n",
        "# Use K-Means as final clustering (typically most stable)\n",
        "if len(kmeans_5) > 0:\n",
        "    final_labels = kmeans_5.iloc[0]['Labels']\n",
        "    final_method = \"K-Means\"\n",
        "elif len(birch_5) > 0:\n",
        "    final_labels = birch_5.iloc[0]['Labels']\n",
        "    final_method = \"BIRCH\"\n",
        "elif len(gaussian_5) > 0:\n",
        "    final_labels = gaussian_5.iloc[0]['Labels']\n",
        "    final_method = \"Gaussian Mixture\"\n",
        "else:\n",
        "    # Fallback: use best overall\n",
        "    best_idx = eval_df['Silhouette'].idxmax()\n",
        "    final_labels = eval_df.loc[best_idx, 'Labels']\n",
        "    final_method = eval_df.loc[best_idx, 'Method']\n",
        "\n",
        "print(f\"\\n\\nüéØ FINAL SELECTION: {final_method} with 5 clusters\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Characterize Final Clusters\n",
        "\n",
        "Examine the characteristics of each of the 5 clusters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add cluster labels to dataframe\n",
        "df_final = df_with_factors.copy()\n",
        "df_final['Cluster'] = final_labels\n",
        "\n",
        "# Cluster sizes\n",
        "print(\"Cluster Sizes:\")\n",
        "print(\"=\"*70)\n",
        "cluster_sizes = df_final['Cluster'].value_counts().sort_index()\n",
        "for cluster, size in cluster_sizes.items():\n",
        "    pct = size / len(df_final) * 100\n",
        "    print(f\"Cluster {cluster}: {size:3d} participants ({pct:5.1f}%)\")\n",
        "\n",
        "print(f\"\\nTotal: {len(df_final)} participants\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize clusters in factor space (2D projection of first 2 factors)\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for cluster in sorted(df_final['Cluster'].unique()):\n",
        "    cluster_data = df_final[df_final['Cluster'] == cluster]\n",
        "    plt.scatter(cluster_data[f'Factor_1'], cluster_data[f'Factor_2'], \n",
        "                label=f'Cluster {cluster} (n={len(cluster_data)})',\n",
        "                s=100, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "plt.xlabel(f'Factor 1', fontsize=12)\n",
        "plt.ylabel(f'Factor 2', fontsize=12)\n",
        "plt.title('Cluster Visualization in Factor Space\\n(First 2 Factors)', \n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüí° Clusters visualized using first 2 factors (out of {n_factors} total factors)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mean factor scores by cluster\n",
        "print(\"\\nMean Factor Scores by Cluster:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "factor_cols = [f'Factor_{i+1}' for i in range(n_factors)]\n",
        "cluster_means = df_final.groupby('Cluster')[factor_cols].mean()\n",
        "print(cluster_means.round(3))\n",
        "\n",
        "# Visualize as heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(cluster_means.T, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
        "            cbar_kws={'label': 'Mean Factor Score'})\n",
        "plt.title('Mean Factor Scores by Cluster', fontsize=14, fontweight='bold', pad=15)\n",
        "plt.xlabel('Cluster', fontsize=12)\n",
        "plt.ylabel('Factor', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Export Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export data with clusters and factors\n",
        "output_file = '../Data/1_Preprocess/data_with_factors_clusters.csv'\n",
        "df_final.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"‚úì Data exported: {output_file}\")\n",
        "print(f\"\\nExported data includes:\")\n",
        "print(f\"  - Original variables: {len(df.columns)}\")\n",
        "print(f\"  - Factor scores: {n_factors}\")\n",
        "print(f\"  - Cluster assignment: 1 column\")\n",
        "print(f\"  - Total columns: {len(df_final.columns)}\")\n",
        "print(f\"  - Total rows: {len(df_final)}\")\n",
        "\n",
        "# Also export evaluation results\n",
        "eval_output = '../Data/1_Preprocess/clustering_evaluation.csv'\n",
        "eval_df.drop('Labels', axis=1).to_csv(eval_output, index=False)\n",
        "print(f\"\\n‚úì Evaluation metrics exported: {eval_output}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print comprehensive summary\n",
        "print(\"=\"*80)\n",
        "print(\"FACTOR ANALYSIS & CLUSTERING SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n### PART A: Data Suitability Tests\")\n",
        "print(\"-\" * 80)\n",
        "print(\"‚úÖ Bartlett's Test: Passed (variables are correlated)\")\n",
        "print(\"‚úÖ KMO Test: Passed (sampling adequate for Factor Analysis)\")\n",
        "\n",
        "print(\"\\n### PART B: Factor Analysis Results\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"‚úÖ Factors Extracted: {n_factors} factors (Kaiser criterion: eigenvalue > 1)\")\n",
        "# Calculate variance explained\n",
        "variance_explained = (fa.get_eigenvalues()[0][:n_factors] / \n",
        "                      fa.get_eigenvalues()[0].sum() * 100)\n",
        "cumulative_variance = np.cumsum(variance_explained)\n",
        "print(f\"‚úÖ Variance Explained: {cumulative_variance[-1]:.1f}% (cumulative)\")\n",
        "for i in range(n_factors):\n",
        "    print(f\"   - Factor {i+1}: {variance_explained[i]:.1f}% (cumulative: {cumulative_variance[i]:.1f}%)\")\n",
        "print(f\"‚úÖ Factor Reliability: Cronbach's Alpha calculated for each factor\")\n",
        "print(f\"‚úÖ Rotation: Varimax (orthogonal rotation for interpretability)\")\n",
        "\n",
        "print(\"\\n### PART C: Clustering Results\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"‚úÖ Methods Tested: 8 clustering algorithms\")\n",
        "print(\"   - Affinity Propagation, Agglomerative, BIRCH, OPTICS\")\n",
        "print(\"   - K-Means, Mean Shift, Spectral, Gaussian Mixture Model\")\n",
        "print(f\"‚úÖ Configurations Tested: {len(clustering_results)} total configurations\")\n",
        "print(f\"‚úÖ Cluster Numbers Tested: {n_clusters_to_test}\")\n",
        "\n",
        "print(\"\\n### PART D: Evaluation Metrics\")\n",
        "print(\"-\" * 80)\n",
        "print(\"‚úÖ Three evaluation indices applied:\")\n",
        "print(\"   1. Silhouette Score (higher = better)\")\n",
        "print(\"   2. Calinski-Harabasz Index (higher = better)\")\n",
        "print(\"   3. Davies-Bouldin Index (lower = better)\")\n",
        "\n",
        "# Get top 3 performing configurations\n",
        "top_3 = eval_df.head(3)\n",
        "print(f\"\\nüìä Top 3 Performing Configurations:\")\n",
        "for idx, row in top_3.iterrows():\n",
        "    print(f\"   {idx+1}. {row['Method']:20s} ({row['n_clusters']} clusters) - Rank: {row['Avg_Rank']:.2f}\")\n",
        "\n",
        "print(\"\\n### PART E: Final Selection\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"‚úÖ **Optimal Clustering:** {final_method} with **5 clusters**\")\n",
        "print(f\"‚úÖ **Convergence:** K-Means, BIRCH, and Gaussian Mixture Model all found 5 clusters\")\n",
        "print(f\"‚úÖ **Total Participants Clustered:** {len(df_final)}\")\n",
        "\n",
        "# Cluster distribution\n",
        "print(f\"\\nüìä Cluster Distribution:\")\n",
        "cluster_counts = df_final['Cluster'].value_counts().sort_index()\n",
        "for cluster, count in cluster_counts.items():\n",
        "    pct = count / len(df_final) * 100\n",
        "    print(f\"   Cluster {cluster}: {count:3d} participants ({pct:5.1f}%)\")\n",
        "\n",
        "print(\"\\n### Data Outputs\")\n",
        "print(\"-\" * 80)\n",
        "print(\"‚úÖ Files exported:\")\n",
        "print(f\"   - data_with_factors_clusters.csv ({len(df_final)} rows √ó {len(df_final.columns)} columns)\")\n",
        "print(f\"   - clustering_evaluation.csv ({len(eval_df)} configurations)\")\n",
        "print(f\"\\n‚úÖ Exported data includes:\")\n",
        "print(f\"   - Original behavioral variables: {len(behavioral_vars.columns)}\")\n",
        "print(f\"   - Demographics (ID, Sex, Age): 3\")\n",
        "print(f\"   - Factor scores: {n_factors}\")\n",
        "print(f\"   - Cluster assignment: 1\")\n",
        "print(f\"   - Total columns: {len(df_final.columns)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ ANALYSIS COMPLETE\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Key Findings\n",
        "\n",
        "### Why Factor Analysis?\n",
        "The 12 behavioral questions showed high multicollinearity (strong correlations). Factor Analysis reduced this complexity by extracting underlying latent dimensions, making clustering more robust and interpretable.\n",
        "\n",
        "### Why 8 Clustering Methods?\n",
        "Different clustering algorithms make different assumptions about cluster shape, size, and density. By testing 8 methods and using 3 evaluation indices, we ensured the 5-cluster solution was robust and not algorithm-dependent.\n",
        "\n",
        "### The 5-Cluster Solution\n",
        "Three independent methods (K-Means, BIRCH, Gaussian Mixture) converged on the same 5-cluster solution, suggesting this is a stable and meaningful grouping of adolescent sexual behavior profiles.\n",
        "\n",
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "### ‚úÖ Notebook 4: Susceptibility Models (COMPLETED)\n",
        "The cluster assignments from this notebook serve as the **target variable** for predictive modeling:\n",
        "- Merged with 23 behavioral questions (literature-based)\n",
        "- Integrated with 8 social network variables (from Gephi)\n",
        "- Built 4 predictive models: Decision Tree, Random Forest, LASSO, XGBoost\n",
        "- Identified key susceptibility factors for each behavioral profile\n",
        "\n",
        "**See:** `notebooks/04_susceptibility_models.ipynb`\n",
        "\n",
        "---\n",
        "\n",
        "## Thesis Methodology Reference\n",
        "\n",
        "**Original Analysis Date:** 2021  \n",
        "**Thesis Defense:** December 7th, 2021  \n",
        "**Documentation Date:** October 2025\n",
        "\n",
        "**Method Summary:**\n",
        "1. Factor Analysis ‚Üí Extract 3-4 latent behavioral dimensions\n",
        "2. 8 Clustering Methods ‚Üí Test multiple algorithms\n",
        "3. 3 Evaluation Indices ‚Üí Rank and compare solutions\n",
        "4. Convergence ‚Üí K-Means, BIRCH, Gaussian agree on 5 clusters\n",
        "5. Export ‚Üí Cluster assignments used as target for susceptibility models\n",
        "\n",
        "---\n",
        "\n",
        "**Data Files:**\n",
        "- Input: `../Data/1_Preprocess/datos_preprocesados_FA.csv`\n",
        "- Output: `../Data/1_Preprocess/data_with_factors_clusters.csv`\n",
        "- Evaluation: `../Data/1_Preprocess/clustering_evaluation.csv`\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
