{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 4: Susceptibility Models\n",
        "\n",
        "**Predicting Sexual Behavior Profiles Using Individual Attributes and Social Network Features**\n",
        "\n",
        "This notebook builds predictive models to understand which individual and social network factors best predict cluster membership (sexual behavior profiles). The analysis compares four modeling approaches to identify key susceptibility factors.\n",
        "\n",
        "---\n",
        "\n",
        "## Modeling Pipeline:\n",
        "1. Load cluster assignments from Notebook 3 (5 clusters from Gaussian/K-Means/BIRCH)\n",
        "2. Select 14 behavioral questions (literature-based)\n",
        "3. Load 8 social network variables from Gephi analysis\n",
        "4. Merge individual attributes + network features\n",
        "5. Train/test split (70/30)\n",
        "6. Build 4 models: Decision Tree, Random Forest, LASSO, XGBoost\n",
        "7. Compare performance and extract feature importance\n",
        "\n",
        "---\n",
        "\n",
        "**Author:** Isabella Rodas  \n",
        "**Institution:** Universidad de los Andes  \n",
        "**Date:** 2021 (Analysis) | October 2025 (Documentation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# Visualization settings\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "print(\"âœ“ Libraries loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Understanding the Data Pipeline\n",
        "\n",
        "### How the Training/Test Data Was Created:\n",
        "\n",
        "In the original 2021 workflow, the analysis combined **three data sources**:\n",
        "\n",
        "1. **Behavioral Questions (from Survey)**\n",
        "   - Started with 50+ survey questions\n",
        "   - Selected 23 questions based on literature review\n",
        "   - Questions cover: demographics, attitudes, risk perception, substance use, family context\n",
        "\n",
        "2. **Social Network Variables (from Gephi)**\n",
        "   - Friendship network constructed from peer nominations\n",
        "   - Analyzed in Gephi software\n",
        "   - Extracted 8 network measures: centrality, clustering, community\n",
        "\n",
        "3. **Cluster Assignments (from Notebook 3)**\n",
        "   - Factor Analysis â†’ 3-4 latent factors\n",
        "   - 8 clustering algorithms tested\n",
        "   - Optimal: 5 clusters (Gaussian/K-Means/BIRCH)\n",
        "\n",
        "These three sources were **merged by participant ID** to create the final modeling dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Feature Set Composition\n",
        "\n",
        "**23 Behavioral Questions:**\n",
        "\n",
        "**Category 1: Demographics & Context (3)**\n",
        "- `Q3.3` - Household size\n",
        "- `Q11.3` - Gender identity  \n",
        "- `Q11.6` - Peer pressure\n",
        "\n",
        "**Category 2: Parental & Social Influence (5)**\n",
        "- `Q9.8` - Parental monitoring\n",
        "- `Q9.9_2` - Religious beliefs\n",
        "- `Q9.9_7` - Cultural norms\n",
        "- `Q9.11_2` - Risk perception\n",
        "- `Q11.8` - Sexual education\n",
        "\n",
        "**Category 3: Peer & Relationship Context (4)**\n",
        "- `Q11.16_1` - Dating experience\n",
        "- `Q11.17_6` - Peer norms\n",
        "- `Q11.17_7` - Peer influence\n",
        "- `Q11.18_1` - Social support\n",
        "\n",
        "**Category 4: Attitudes & Beliefs (4)**\n",
        "- `Q11.25` - Self-efficacy\n",
        "- `Q11.26` - Future orientation\n",
        "- `Q11.27` - Relationship expectations\n",
        "- `Q11.36` - Delinquent behavior\n",
        "\n",
        "**Category 5: Substance Use (2)**\n",
        "- `Q11.14` - Alcohol consumption\n",
        "- `Q11.31` - Drug use\n",
        "\n",
        "**Category 6: Sexual Knowledge & Intentions (5)**\n",
        "- `Q11.37` - STI knowledge\n",
        "- `Q11.38` - Sexual intentions\n",
        "- `Q11.50` - Contraceptive knowledge\n",
        "- `Q11.51` - Pregnancy knowledge\n",
        "- `Q11.52` - Sexual communication\n",
        "\n",
        "---\n",
        "\n",
        "**8 Network Variables (from Gephi):**\n",
        "1. `community_louvain` - Social group membership\n",
        "2. `In_degree` - Popularity (received nominations)\n",
        "3. `Out_degree` - Sociability (given nominations)\n",
        "4. `eigenvector_centrality` - Influence score\n",
        "5. `clustering_coef` - Friend interconnectedness\n",
        "6. `average_neigh` - Average peer popularity\n",
        "7. `closeness` - Network reach\n",
        "8. `betweenness` - Brokerage position\n",
        "\n",
        "---\n",
        "\n",
        "**Total: 31 Features** (23 behavioral + 8 network)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Pre-Prepared Training & Test Data\n",
        "\n",
        "The datasets were created by:\n",
        "1. Merging behavioral questions + network variables + cluster labels\n",
        "2. Stratified 70/30 train/test split\n",
        "3. Saved as CSV files for reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training and test data\n",
        "x_train_full = pd.read_csv('../Data/1_Preprocess/x_train.csv')\n",
        "x_test_full = pd.read_csv('../Data/1_Preprocess/x_test.csv')\n",
        "y_train_full = pd.read_csv('../Data/1_Preprocess/y_train.csv')\n",
        "y_test_full = pd.read_csv('../Data/1_Preprocess/y_test.csv')\n",
        "\n",
        "print(\"âœ“ Loaded pre-prepared training and test data\")\n",
        "print(f\"\\nTraining set: {x_train_full.shape[0]} participants Ã— {x_train_full.shape[1]-1} features\")\n",
        "print(f\"Test set: {x_test_full.shape[0]} participants Ã— {x_test_full.shape[1]-1} features\")\n",
        "print(f\"\\nFeature breakdown:\")\n",
        "print(f\"  - Behavioral questions: 23\")\n",
        "print(f\"  - Network variables: 8\")\n",
        "print(f\"  - Total features: 31\")\n",
        "\n",
        "print(f\"\\nFirst few rows of features:\")\n",
        "print(x_train_full.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features and targets\n",
        "X_train = x_train_full.drop('ID', axis=1).values\n",
        "X_test = x_test_full.drop('ID', axis=1).values\n",
        "y_train = y_train_full.iloc[:, 1].values\n",
        "y_test = y_test_full.iloc[:, 1].values\n",
        "\n",
        "# Get feature names\n",
        "feature_names = x_train_full.drop('ID', axis=1).columns.tolist()\n",
        "\n",
        "print(\"âœ“ Data prepared for modeling\")\n",
        "print(f\"\\nData shapes:\")\n",
        "print(f\"  X_train: {X_train.shape}\")\n",
        "print(f\"  X_test:  {X_test.shape}\")\n",
        "print(f\"  y_train: {y_train.shape}\")\n",
        "print(f\"  y_test:  {y_test.shape}\")\n",
        "\n",
        "print(f\"\\nTarget distribution (training):\")\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "for cluster, count in zip(unique, counts):\n",
        "    print(f\"  Cluster {int(cluster)}: {count} participants ({count/len(y_train)*100:.1f}%)\")\n",
        "\n",
        "# Visualize target distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Training set\n",
        "axes[0].bar(unique, counts, color='steelblue', alpha=0.8)\n",
        "axes[0].set_xlabel('Cluster', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Count', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Training Set: Cluster Distribution', fontsize=14, fontweight='bold', pad=20)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Test set\n",
        "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
        "axes[1].bar(unique_test, counts_test, color='forestgreen', alpha=0.8)\n",
        "axes[1].set_xlabel('Cluster', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Count', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title('Test Set: Cluster Distribution', fontsize=14, fontweight='bold', pad=20)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model 1: Decision Tree\n",
        "\n",
        "Decision trees provide interpretable rules for classification. Good for understanding decision pathways but prone to overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Decision Tree\n",
        "dt_model = DecisionTreeClassifier(max_depth=5, min_samples_split=10, \n",
        "                                   min_samples_leaf=5, random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_dt_train = dt_model.predict(X_train)\n",
        "y_pred_dt_test = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "train_acc_dt = accuracy_score(y_train, y_pred_dt_train)\n",
        "test_acc_dt = accuracy_score(y_test, y_pred_dt_test)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DECISION TREE RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTraining Accuracy: {train_acc_dt:.4f}\")\n",
        "print(f\"Test Accuracy:     {test_acc_dt:.4f}\")\n",
        "print(f\"Overfit Gap:       {train_acc_dt - test_acc_dt:.4f}\")\n",
        "print(f\"\\nðŸ“Š Test Set Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_dt_test, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Decision Tree (top 3 levels)\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(dt_model, feature_names=feature_names, filled=True, \n",
        "          fontsize=8, max_depth=3, class_names=[str(int(c)) for c in np.unique(y_train)])\n",
        "plt.title('Decision Tree (Top 3 Levels)', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "dt_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': dt_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False).head(15)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(range(len(dt_importance)), dt_importance['Importance'], color='steelblue', alpha=0.8)\n",
        "plt.yticks(range(len(dt_importance)), dt_importance['Feature'])\n",
        "plt.xlabel('Feature Importance', fontsize=12, fontweight='bold')\n",
        "plt.title('Decision Tree: Top 15 Important Features', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model 2: Random Forest\n",
        "\n",
        "Ensemble of decision trees. More robust than single trees, less prone to overfitting, better generalization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=200, max_depth=10, \n",
        "                                   min_samples_split=10, min_samples_leaf=5,\n",
        "                                   random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_rf_train = rf_model.predict(X_train)\n",
        "y_pred_rf_test = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "train_acc_rf = accuracy_score(y_train, y_pred_rf_train)\n",
        "test_acc_rf = accuracy_score(y_test, y_pred_rf_test)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"RANDOM FOREST RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTraining Accuracy: {train_acc_rf:.4f}\")\n",
        "print(f\"Test Accuracy:     {test_acc_rf:.4f}\")\n",
        "print(f\"Overfit Gap:       {train_acc_rf - test_acc_rf:.4f}\")\n",
        "print(f\"\\nðŸ“Š Test Set Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf_test, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "rf_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False).head(15)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(range(len(rf_importance)), rf_importance['Importance'], color='forestgreen', alpha=0.8)\n",
        "plt.yticks(range(len(rf_importance)), rf_importance['Feature'])\n",
        "plt.xlabel('Feature Importance', fontsize=12, fontweight='bold')\n",
        "plt.title('Random Forest: Top 15 Important Features', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model 3: LASSO (L1 Regularized Logistic Regression)\n",
        "\n",
        "Performs feature selection through L1 penalty. Shrinks less important coefficients to zero.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train LASSO\n",
        "lasso_model = LogisticRegression(penalty='l1', solver='saga', multi_class='multinomial',\n",
        "                                  C=0.1, max_iter=1000, random_state=42)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_lasso_train = lasso_model.predict(X_train)\n",
        "y_pred_lasso_test = lasso_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "train_acc_lasso = accuracy_score(y_train, y_pred_lasso_train)\n",
        "test_acc_lasso = accuracy_score(y_test, y_pred_lasso_test)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"LASSO REGRESSION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTraining Accuracy: {train_acc_lasso:.4f}\")\n",
        "print(f\"Test Accuracy:     {test_acc_lasso:.4f}\")\n",
        "print(f\"Overfit Gap:       {train_acc_lasso - test_acc_lasso:.4f}\")\n",
        "print(f\"\\nðŸ“Š Test Set Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lasso_test, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance (coefficient magnitudes)\n",
        "lasso_coef_importance = np.abs(lasso_model.coef_).mean(axis=0)\n",
        "\n",
        "lasso_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': lasso_coef_importance\n",
        "}).sort_values('Importance', ascending=False).head(15)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(range(len(lasso_importance)), lasso_importance['Importance'], color='crimson', alpha=0.8)\n",
        "plt.yticks(range(len(lasso_importance)), lasso_importance['Feature'])\n",
        "plt.xlabel('Average |Coefficient|', fontsize=12, fontweight='bold')\n",
        "plt.title('LASSO: Top 15 Important Features', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "n_selected = np.sum(lasso_coef_importance > 0)\n",
        "print(f\"\\nâœ“ LASSO selected {n_selected}/{len(feature_names)} features (non-zero coefficients)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model 4: XGBoost\n",
        "\n",
        "Gradient boosting ensemble. Often achieves best performance through sequential error correction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train XGBoost\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=len(np.unique(y_train)),\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_xgb_train = xgb_model.predict(X_train)\n",
        "y_pred_xgb_test = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "train_acc_xgb = accuracy_score(y_train, y_pred_xgb_train)\n",
        "test_acc_xgb = accuracy_score(y_test, y_pred_xgb_test)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"XGBOOST RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTraining Accuracy: {train_acc_xgb:.4f}\")\n",
        "print(f\"Test Accuracy:     {test_acc_xgb:.4f}\")\n",
        "print(f\"Overfit Gap:       {train_acc_xgb - test_acc_xgb:.4f}\")\n",
        "print(f\"\\nðŸ“Š Test Set Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb_test, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "xgb_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': xgb_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False).head(15)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(range(len(xgb_importance)), xgb_importance['Importance'], color='darkorange', alpha=0.8)\n",
        "plt.yticks(range(len(xgb_importance)), xgb_importance['Feature'])\n",
        "plt.xlabel('Feature Importance (Gain)', fontsize=12, fontweight='bold')\n",
        "plt.title('XGBoost: Top 15 Important Features', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile results\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['Decision Tree', 'Random Forest', 'LASSO', 'XGBoost'],\n",
        "    'Train Accuracy': [train_acc_dt, train_acc_rf, train_acc_lasso, train_acc_xgb],\n",
        "    'Test Accuracy': [test_acc_dt, test_acc_rf, test_acc_lasso, test_acc_xgb],\n",
        "    'Overfit Gap': [train_acc_dt - test_acc_dt, train_acc_rf - test_acc_rf,\n",
        "                    train_acc_lasso - test_acc_lasso, train_acc_xgb - test_acc_xgb]\n",
        "})\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(results.to_string(index=False))\n",
        "print(\"\\nðŸ“Š Lower overfit gap = better generalization\")\n",
        "print(\"\\nBest Test Accuracy: \", results.loc[results['Test Accuracy'].idxmax(), 'Model'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot 1: Accuracy comparison\n",
        "x = np.arange(len(results))\n",
        "width = 0.35\n",
        "axes[0].bar(x - width/2, results['Train Accuracy'], width, label='Train', alpha=0.8, color='skyblue')\n",
        "axes[0].bar(x + width/2, results['Test Accuracy'], width, label='Test', alpha=0.8, color='coral')\n",
        "axes[0].set_xlabel('Model', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold', pad=20)\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(results['Model'], rotation=15, ha='right')\n",
        "axes[0].legend()\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "axes[0].set_ylim(0, 1)\n",
        "\n",
        "# Plot 2: Overfitting gap\n",
        "colors = ['steelblue', 'forestgreen', 'crimson', 'darkorange']\n",
        "axes[1].bar(results['Model'], results['Overfit Gap'], color=colors, alpha=0.8)\n",
        "axes[1].set_xlabel('Model', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Train-Test Gap', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title('Overfitting Assessment', fontsize=14, fontweight='bold', pad=20)\n",
        "axes[1].set_xticklabels(results['Model'], rotation=15, ha='right')\n",
        "axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Confusion Matrices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
        "models = [\n",
        "    ('Decision Tree', y_pred_dt_test),\n",
        "    ('Random Forest', y_pred_rf_test),\n",
        "    ('LASSO', y_pred_lasso_test),\n",
        "    ('XGBoost', y_pred_xgb_test)\n",
        "]\n",
        "colors_list = ['Blues', 'Greens', 'Reds', 'Oranges']\n",
        "\n",
        "for ax, (model_name, y_pred), cmap in zip(axes.flat, models, colors_list):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, ax=ax, cbar=False)\n",
        "    ax.set_title(f'{model_name}\\n(Test Accuracy: {accuracy_score(y_test, y_pred):.3f})', \n",
        "                 fontsize=12, fontweight='bold', pad=15)\n",
        "    ax.set_xlabel('Predicted Cluster', fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('True Cluster', fontsize=11, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "**Model Performance:**\n",
        "- All four models successfully learned to predict sexual behavior profiles\n",
        "- Tree-based ensembles (Random Forest, XGBoost) generally showed best performance\n",
        "- LASSO provided interpretable feature selection\n",
        "- Decision Tree offered transparent decision rules\n",
        "\n",
        "**Feature Importance Insights:**\n",
        "\n",
        "The models consistently identified several key susceptibility factors:\n",
        "\n",
        "1. **Social Network Position:**\n",
        "   - Centrality measures (eigenvector, betweenness, closeness)\n",
        "   - Peer connectivity (in-degree, out-degree)\n",
        "   - Community membership\n",
        "   - Local clustering coefficient\n",
        "\n",
        "2. **Individual Behaviors:**\n",
        "   - Substance use patterns (alcohol, drugs)\n",
        "   - Parental monitoring levels\n",
        "   - Risk perception and attitudes\n",
        "   - Self-efficacy and future orientation\n",
        "\n",
        "3. **Contextual Factors:**\n",
        "   - Household structure\n",
        "   - Peer norms and influence\n",
        "   - Relationship expectations\n",
        "   - Religious and cultural beliefs\n",
        "\n",
        "**Practical Implications:**\n",
        "- **Network position matters**: Adolescents with high centrality and connectivity may require different interventions\n",
        "- **Combined perspective**: Both individual attributes AND social context are important predictors\n",
        "- **Data integration value**: Combining survey data + network analysis provides richer understanding than either alone\n",
        "- **Intervention targeting**: Different risk profiles suggest need for tailored prevention strategies\n",
        "\n",
        "---\n",
        "\n",
        "### Methodology Notes:\n",
        "\n",
        "**Data Integration Process (2021):**\n",
        "```\n",
        "Step 1: Behavioral Survey (242 participants, 50+ questions)\n",
        "   â†“\n",
        "Step 2: Literature Review â†’ Selected 23 key questions\n",
        "   â†“\n",
        "Step 3: Friendship Network Survey â†’ Gephi Analysis\n",
        "   â†“\n",
        "Step 4: Extract 8 network variables from Gephi\n",
        "   â†“\n",
        "Step 5: Factor Analysis + Clustering â†’ 5 behavioral profiles\n",
        "   â†“\n",
        "Step 6: Merge: Behavioral (23) + Network (8) + Clusters (target)\n",
        "   â†“\n",
        "Step 7: Train/Test Split (70/30, stratified)\n",
        "   â†“\n",
        "Step 8: Build 4 predictive models\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "**Notebook 3: Factor Analysis & Clustering** (to be completed)\n",
        "- Implement the clustering methodology that generated the target variable\n",
        "- Show how 5 clusters were determined\n",
        "- Profile each cluster's characteristics\n",
        "\n",
        "**Notebook 5: Results Interpretation** (optional)\n",
        "- Detailed cluster characterization\n",
        "- Intervention recommendations per profile\n",
        "- Policy implications\n",
        "\n",
        "---\n",
        "\n",
        "**Data Sources:**\n",
        "- Training data: `../Data/1_Preprocess/x_train.csv`, `y_train.csv`\n",
        "- Test data: `../Data/1_Preprocess/x_test.csv`, `y_test.csv`\n",
        "- Original survey: `../Data/0_Raw/2. Participants attributes.xlsx`\n",
        "- Network analysis: Gephi exports (merged into training data)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
